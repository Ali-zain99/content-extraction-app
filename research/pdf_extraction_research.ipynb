{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0dca88d",
   "metadata": {},
   "source": [
    "# Installing Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "120b7853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pdf2image\n",
      "  Using cached pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: pillow in c:\\users\\ali.zain\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pdf2image) (11.2.1)\n",
      "Downloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
      "Installing collected packages: pdf2image\n",
      "Successfully installed pdf2image-1.17.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install pdf2image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "533c3616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-generativeai in c:\\users\\ali.zain\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.8.5)\n",
      "Requirement already satisfied: PyPDF2 in c:\\users\\ali.zain\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.0.1)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\ali.zain\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.1.1)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in c:\\users\\ali.zain\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-generativeai) (0.6.15)\n",
      "Requirement already satisfied: google-api-core in c:\\users\\ali.zain\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-generativeai) (2.25.1)\n",
      "Requirement already satisfied: google-api-python-client in c:\\users\\ali.zain\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-generativeai) (2.176.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in c:\\users\\ali.zain\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-generativeai) (2.40.3)\n",
      "Requirement already satisfied: protobuf in c:\\users\\ali.zain\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-generativeai) (5.29.5)\n",
      "Requirement already satisfied: pydantic in c:\\users\\ali.zain\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-generativeai) (2.11.7)\n",
      "Requirement already satisfied: tqdm in c:\\users\\ali.zain\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-generativeai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\ali.zain\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-generativeai) (4.14.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\ali.zain\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in c:\\users\\ali.zain\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-api-core->google-generativeai) (1.70.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in c:\\users\\ali.zain\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-api-core->google-generativeai) (2.32.4)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in c:\\users\\ali.zain\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.73.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in c:\\users\\ali.zain\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\ali.zain\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\ali.zain\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\ali.zain\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\ali.zain\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ali.zain\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ali.zain\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ali.zain\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.6.15)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\ali.zain\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
      "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in c:\\users\\ali.zain\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in c:\\users\\ali.zain\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\users\\ali.zain\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\ali.zain\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\ali.zain\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic->google-generativeai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\ali.zain\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic->google-generativeai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\ali.zain\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic->google-generativeai) (0.4.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\ali.zain\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm->google-generativeai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install google-generativeai PyPDF2 python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77461f9",
   "metadata": {},
   "source": [
    "# Event Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "17463e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ JSON saved to gemini_response.json\n",
      "```json\n",
      "{\n",
      "  \"Event name\": \"Enormous Geothermal Systems to 2026\",\n",
      "  \"Event code\": \"AFS\",\n",
      "  \"Event Tagline\": \"Enormous Geothermal Systems to 2026\",\n",
      "  \"Event Dates\": \"March 11 - March 23, 2026\",\n",
      "  \"Event Location\": \"Los Angeles, California, USA\",\n",
      "  \"Event year\": \"2026\",\n",
      "  \"Event Currency\": \"USD\",\n",
      "  \"Event Short Dates\": \"Mar - Mar, 2026\",\n",
      "  \"Event Short Location\": \"CA\",\n",
      "  \"Event Color Name\": \"Enormous\",\n",
      "  \"Event City Shortcode\": \"LA\",\n",
      "  \"Event Postponed\": false,\n",
      "  \"Industry Name\": \"Clean Energy\",\n",
      "  \"Previous Agenda\": false,\n",
      "  \"Hubspot Disposition\": \"disposition_afs_2026\",\n",
      "  \"Hubspot Email Status\": \"email_afs_2026\",\n",
      "  \"Custom Currency Symbol\": \"\",\n",
      "  \"Currency Position\": \"Top left\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "from pdf2image import convert_from_path\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# 1. Configure Gemini API\n",
    "genai.configure(api_key=\"AIzaSyDDoos-ITDh0hl694HB2um_iqdu36jREAw\")\n",
    "\n",
    "# 2. Extract pages of PDF as a PIL image\n",
    "def get_page_image(pdf_path, page_num):\n",
    "    images = convert_from_path(\n",
    "        pdf_path,\n",
    "        first_page=page_num,\n",
    "        last_page=page_num,\n",
    "        poppler_path=r\"C:\\Users\\ali.zain\\Desktop\\poppler-24.08.0\\Library\\bin\"\n",
    "    )\n",
    "    if images:\n",
    "        return images[0]  # Return PIL.Image.Image object\n",
    "    return None\n",
    "\n",
    "# 3. Run OCR using Gemini 2.0 Flash\n",
    "def ocr_with_gemini(pil_image, query):\n",
    "    model = genai.GenerativeModel(\"gemma-3-4b-it\")\n",
    "    response = model.generate_content([\n",
    "        query,\n",
    "        pil_image\n",
    "    ])\n",
    "    return response.text.strip()\n",
    "\n",
    "# 4. Prompt builder for event details\n",
    "def build_prompt(first_page_text, industry_name):\n",
    "    return f\"\"\"\n",
    "You are given text from the first page of a PDF (event details) and an extracted \"Industry Name\".\n",
    "\n",
    "Rules:\n",
    "1. \"Event name\" – Use the event name , after removing first word and last word year.\n",
    "2. \"Event code\" – Use the event code exactly as shown.\n",
    "3. \"Event Tagline\" – Use the full event name except year .\n",
    "3. \"Event Dates\" – Format as \"Month, Date1 - Date2, YYYY\".\n",
    "4. \"Event Location\" – Full location (City, State/Region, Country).\n",
    "5. \"Event year\" – 4-digit year from the event date.\n",
    "6. \"Event Currency\" – Based on country (USA →  USD, Canada → CAD, Eurozone → EUR).\n",
    "7. \"Event Short Dates\" – Format as \"Month(In short form), Date1 - Date2, YYYY\".\n",
    "8. \"Event Short Location\" – Abbreviated form of Event Location contain only state (remove city and country if present, keep state short form).\n",
    "9. \"Event Color Name\" – first word of the event name.\n",
    "10. \"Event City Shortcode\" – First three letters of the city in uppercase.\n",
    "11. \"Event Postponed\" – False unless stated otherwise.\n",
    "12. Add an extra field called \"Industry Name\" – value is \"{industry_name}\".\n",
    "13. \"Previous Agenda\" – True unless stated otherwise.\n",
    "14. \"Hubspot Disposition\" – Format: disposition_<EventCode in lowercase>_<EventYear>\n",
    "15. \"Hubspot Email Status\" – Format: email_status_<EventCode in lowercase>_<EventYear>\n",
    "16. \"Custom Currency Symbol\" – leave it blank.\n",
    "17. \"Currency Position\" – Always \"Top left\".\n",
    "\n",
    "\n",
    "JSON template:\n",
    "{{\n",
    "  \"Event name\": \"\",  \n",
    "  \"Event code\": \"\",  \n",
    "  \"Event Tagline\": \"\",\n",
    "  \"Event Dates\": \"\",  \n",
    "  \"Event Location\": \"\",  \n",
    "  \"Event year\": \"\",  \n",
    "  \"Event Currency\": \"\", \n",
    "  \"Event Short Dates\": \"\", \n",
    "  \"Event Short Location\": \"\", \n",
    "  \"Event Color Name\": \"\", \n",
    "  \"Event City Shortcode\": \"\",  \n",
    "  \"Event Postponed\": false,  \n",
    "  \"Industry Name\": \"\",\n",
    "  \"Previous Agenda\": false,  \n",
    "  \"Hubspot Disposition\": \"\",  \n",
    "  \"Hubspot Email Status\": \"\",  \n",
    "  \"Custom Currency Symbol\": \"\",\n",
    "  \"Currency Position\": \"Top left\"\n",
    "}}\n",
    "\n",
    "First page text:\n",
    "---\n",
    "{first_page_text}\n",
    "---\n",
    "\n",
    "Now return ONLY valid JSON with the filled details.\n",
    "\"\"\"\n",
    "\n",
    "# 5. Main\n",
    "if __name__ == \"__main__\":\n",
    "    pdf_path = r\"C:\\Users\\ali.zain\\Desktop\\Content_Extraction\\content.pdf\"\n",
    "\n",
    "    # Extract first page and second-last page\n",
    "    first_page_img = get_page_image(pdf_path, 1)\n",
    "    industry_page_img = get_page_image(pdf_path, 20)  \n",
    "\n",
    "    if first_page_img and industry_page_img:\n",
    "        # Extract text from first page\n",
    "        first_page_text = ocr_with_gemini(\n",
    "            first_page_img,\n",
    "            \"Extract all the text exactly as shown from this page.\"\n",
    "        )\n",
    "\n",
    "        # Extract industry name from second-last page\n",
    "        industry_name = ocr_with_gemini(\n",
    "            industry_page_img,\n",
    "            \"From the provided form image, identify the industry option that is marked or checked. Return only the industry name (e.g., 'Clean Energy').\"\n",
    "        )\n",
    "\n",
    "        # Build prompt including industry name\n",
    "        prompt = build_prompt(first_page_text, industry_name)\n",
    "\n",
    "        # Run Gemini for final structured JSON\n",
    "        model = genai.GenerativeModel(\"gemma-3-4b-it\")\n",
    "        response = model.generate_content([prompt])\n",
    "\n",
    "        # Save output JSON\n",
    "        with open(\"gemini_response.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(response.text)\n",
    "\n",
    "        print(\"✅ JSON saved to gemini_response.json\")\n",
    "        print(response.text)\n",
    "\n",
    "    else:\n",
    "        print(\"❌ Could not extract images from PDF.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "8bfcb0f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Payload saved to C:\\Users\\ali.zain\\Desktop\\Content_Extraction\\research\\gemini_response_payload.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# Input file path\n",
    "input_file = r\"C:\\Users\\ali.zain\\Desktop\\Content_Extraction\\research\\gemini_response.json\"\n",
    "\n",
    "# Load JSON from file\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_content = f.read().strip()\n",
    "clean_content = re.sub(r\"^```[a-zA-Z]*\\n\", \"\", raw_content)\n",
    "clean_content = re.sub(r\"\\n```$\", \"\", clean_content)\n",
    "event_data = json.loads(clean_content)\n",
    "# Map event_data keys to payload options\n",
    "# Format: (json_key, option_name, label)\n",
    "mapping = [\n",
    "    (\"Event name\", \"event_name\", \"Event Name\"),\n",
    "    (\"Event code\", \"event_code\", \"Event Code\"),\n",
    "    (\"Event Tagline\", \"event_tagline\", \"Event Tagline\"),\n",
    "    (\"Event Dates\", \"event_dates\", \"Event Dates\"),\n",
    "    (\"Event Location\", \"event_Location\", \"Event Location\"),\n",
    "    (\"Event year\", \"event_year\", \"Event Year\"),\n",
    "    (\"Event Currency\", \"event_currency\", \"Event Currency\"),\n",
    "    (\"Event Short Dates\", \"event_short_date\", \"Event Short Date\"),\n",
    "    (\"Event Short Location\", \"event_short_location\", \"Event Short Location\"),\n",
    "    (\"Event Color Name\", \"event_color_name\", \"Event Color Name\"),\n",
    "    (\"Event City Shortcode\", \"event_city_shortcode\", \"Event City Shortcode\"),\n",
    "    (\"Event Postponed\", \"event_postponed\", \"Event Postponed\"),\n",
    "    (\"Industry Name\", \"industry_name\", \"Industry Name\"),\n",
    "    (\"Previous Agenda\", \"previous_agenda\", \"Previous Agenda\"),\n",
    "    (\"Hubspot Disposition\", \"hubspot_disposition\", \"Hubspot Disposition\"),\n",
    "    (\"Hubspot Email Status\", \"hubspot_email_status\", \"Hubspot Email Status\"),\n",
    "    (\"Custom Currency Symbol\", \"custom_currency_symbol\", \"Custom Currency Symbol\"),\n",
    "    (\"Currency Position\", \"currency_postion\", \"Currency Postion\"),\n",
    "]\n",
    "\n",
    "# Build payload\n",
    "payload = {\"options\": []}\n",
    "\n",
    "for idx, (json_key, option, label) in enumerate(mapping, start=1):\n",
    "    value = event_data.get(json_key, None)\n",
    "\n",
    "    # Convert booleans to lowercase strings to match your sample payload\n",
    "    if isinstance(value, bool):\n",
    "        value = str(value).lower()\n",
    "\n",
    "    payload[\"options\"].append({\n",
    "        \"id\": idx,\n",
    "        \"option\": option,\n",
    "        \"value\": value,\n",
    "        \"label\": label\n",
    "    })\n",
    "\n",
    "# Output result\n",
    "output_file = os.path.splitext(input_file)[0] + \"_payload.json\"\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(payload, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"✅ Payload saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "9319c191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Response JSON: [\n",
      "  {\n",
      "    \"id\": 1,\n",
      "    \"option\": \"event_name\",\n",
      "    \"value\": \"Enormous Geothermal Systems to 2026\",\n",
      "    \"label\": \"Event Name\",\n",
      "    \"createdAt\": \"2025-08-25T10:31:46.734Z\",\n",
      "    \"updatedAt\": \"2025-08-25T10:31:46.734Z\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": 2,\n",
      "    \"option\": \"event_code\",\n",
      "    \"value\": \"AFS\",\n",
      "    \"label\": \"Event Code\",\n",
      "    \"createdAt\": \"2025-08-25T10:31:46.734Z\",\n",
      "    \"updatedAt\": \"2025-08-25T10:31:46.734Z\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": 3,\n",
      "    \"option\": \"event_tagline\",\n",
      "    \"value\": \"Enormous Geothermal Systems to 2026\",\n",
      "    \"label\": \"Event Tagline\",\n",
      "    \"createdAt\": \"2025-08-25T10:31:46.734Z\",\n",
      "    \"updatedAt\": \"2025-08-25T10:31:46.734Z\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": 4,\n",
      "    \"option\": \"event_dates\",\n",
      "    \"value\": \"March 11 - March 23, 2026\",\n",
      "    \"label\": \"Event Dates\",\n",
      "    \"createdAt\": \"2025-08-25T10:31:46.734Z\",\n",
      "    \"updatedAt\": \"2025-08-25T10:31:46.734Z\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": 5,\n",
      "    \"option\": \"event_Location\",\n",
      "    \"value\": \"Los Angeles, California, USA\",\n",
      "    \"label\": \"Event Location\",\n",
      "    \"createdAt\": \"2025-08-25T10:31:46.734Z\",\n",
      "    \"updatedAt\": \"2025-08-25T10:31:46.734Z\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": 6,\n",
      "    \"option\": \"event_year\",\n",
      "    \"value\": \"2026\",\n",
      "    \"label\": \"Event Year\",\n",
      "    \"createdAt\": \"2025-08-25T10:31:46.734Z\",\n",
      "    \"updatedAt\": \"2025-08-25T10:31:46.734Z\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": 7,\n",
      "    \"option\": \"event_currency\",\n",
      "    \"value\": \"USD\",\n",
      "    \"label\": \"Event Currency\",\n",
      "    \"createdAt\": \"2025-08-25T10:31:46.734Z\",\n",
      "    \"updatedAt\": \"2025-08-25T10:31:46.734Z\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": 8,\n",
      "    \"option\": \"event_short_date\",\n",
      "    \"value\": \"Mar - Mar, 2026\",\n",
      "    \"label\": \"Event Short Date\",\n",
      "    \"createdAt\": \"2025-08-25T10:31:46.734Z\",\n",
      "    \"updatedAt\": \"2025-08-25T10:31:46.734Z\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": 9,\n",
      "    \"option\": \"event_short_location\",\n",
      "    \"value\": \"CA\",\n",
      "    \"label\": \"Event Short Location\",\n",
      "    \"createdAt\": \"2025-08-25T10:31:46.734Z\",\n",
      "    \"updatedAt\": \"2025-08-25T10:31:46.734Z\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": 10,\n",
      "    \"option\": \"event_color_name\",\n",
      "    \"value\": \"Enormous\",\n",
      "    \"label\": \"Event Color Name\",\n",
      "    \"createdAt\": \"2025-08-25T10:31:46.734Z\",\n",
      "    \"updatedAt\": \"2025-08-25T10:31:46.734Z\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": 11,\n",
      "    \"option\": \"event_city_shortcode\",\n",
      "    \"value\": \"LA\",\n",
      "    \"label\": \"Event City Shortcode\",\n",
      "    \"createdAt\": \"2025-08-25T10:31:46.734Z\",\n",
      "    \"updatedAt\": \"2025-08-25T10:31:46.734Z\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": 12,\n",
      "    \"option\": \"event_postponed\",\n",
      "    \"value\": \"false\",\n",
      "    \"label\": \"Event Postponed\",\n",
      "    \"createdAt\": \"2025-08-25T10:31:46.734Z\",\n",
      "    \"updatedAt\": \"2025-08-25T10:31:46.734Z\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": 13,\n",
      "    \"option\": \"industry_name\",\n",
      "    \"value\": \"Clean Energy\",\n",
      "    \"label\": \"Industry Name\",\n",
      "    \"createdAt\": \"2025-08-25T10:31:46.734Z\",\n",
      "    \"updatedAt\": \"2025-08-25T10:31:46.734Z\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": 14,\n",
      "    \"option\": \"previous_agenda\",\n",
      "    \"value\": \"false\",\n",
      "    \"label\": \"Previous Agenda\",\n",
      "    \"createdAt\": \"2025-08-25T10:31:46.734Z\",\n",
      "    \"updatedAt\": \"2025-08-25T10:31:46.734Z\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": 15,\n",
      "    \"option\": \"hubspot_disposition\",\n",
      "    \"value\": \"disposition_afs_2026\",\n",
      "    \"label\": \"Hubspot Disposition\",\n",
      "    \"createdAt\": \"2025-08-25T10:31:46.734Z\",\n",
      "    \"updatedAt\": \"2025-08-25T10:31:46.734Z\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": 16,\n",
      "    \"option\": \"hubspot_email_status\",\n",
      "    \"value\": \"email_afs_2026\",\n",
      "    \"label\": \"Hubspot Email Status\",\n",
      "    \"createdAt\": \"2025-08-25T10:31:46.734Z\",\n",
      "    \"updatedAt\": \"2025-08-25T10:31:46.734Z\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": 17,\n",
      "    \"option\": \"custom_currency_symbol\",\n",
      "    \"value\": \"\",\n",
      "    \"label\": \"Custom Currency Symbol\",\n",
      "    \"createdAt\": \"2025-08-25T10:31:46.734Z\",\n",
      "    \"updatedAt\": \"2025-08-25T10:31:46.734Z\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": 18,\n",
      "    \"option\": \"currency_postion\",\n",
      "    \"value\": \"Top left\",\n",
      "    \"label\": \"Currency Postion\",\n",
      "    \"createdAt\": \"2025-08-25T10:31:46.734Z\",\n",
      "    \"updatedAt\": \"2025-08-25T10:31:46.734Z\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# API endpoint\n",
    "url = \"https://ai-demo.genetechz.com/api/event-details\"\n",
    "\n",
    "# JSON payload (from file)\n",
    "with open(\"gemini_response_payload.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    payload = json.load(f)\n",
    "\n",
    "# Make POST request\n",
    "try:\n",
    "    response = requests.post(url, json=payload, timeout=30)  # use `json=` instead of `data=`\n",
    "    response.raise_for_status()  # raise error for 4xx/5xx responses\n",
    "\n",
    "    # If response is JSON\n",
    "    try:\n",
    "        print(\"✅ Response JSON:\", json.dumps(response.json(), indent=2))\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"⚠️ Response is not valid JSON. Raw text:\")\n",
    "        print(response.text)\n",
    "\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(\"❌ Request failed:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db69651f",
   "metadata": {},
   "source": [
    "# Page Home"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "d3afe674",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt():\n",
    "    return f\"\"\"\n",
    "You are an expert information extraction AI. Given the OCR text of a webpage, identify and extract the heading and descriptive text associated with the section featuring a video element. The heading and descriptive text are presented near the following lines:\n",
    "Event Logo\n",
    "EVENT DETAILS SPEAKERS\n",
    "SPONSORS VENUE MEDIA CONTACT US\n",
    "REGISTER\n",
    "and a video element.\n",
    "Return the extracted heading and description in JSON format, where the keys are 'heading' and 'description', and the values are the corresponding text strings from the document. Ensure the 'description' value includes all text intended to describe the video section, presented in a concise and readable manner with original linebreaks.\n",
    "If a video section cannot be confidently identified, return an empty JSON object: \n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "96b89ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import google.generativeai as genai\n",
    "\n",
    "def resize_image(pil_image, max_size=2000, save_path=\"resized_page.png\"):\n",
    "    \"\"\"Resize image to max_size while keeping aspect ratio. Save for inspection.\"\"\"\n",
    "    width, height = pil_image.size\n",
    "    if max(width, height) > max_size:\n",
    "        if width > height:\n",
    "            new_width = max_size\n",
    "            new_height = int(height * (max_size / width))\n",
    "        else:\n",
    "            new_height = max_size\n",
    "            new_width = int(width * (max_size / height))\n",
    "        pil_image = pil_image.resize((new_width, new_height), Image.LANCZOS)\n",
    "    # Save to disk so you can verify what Gemini sees\n",
    "    pil_image.save(save_path)\n",
    "    print(f\"📸 Resized image saved at {os.path.abspath(save_path)} ({pil_image.size[0]}x{pil_image.size[1]})\")\n",
    "    return pil_image\n",
    "\n",
    "def ocr_with_gemini(pil_image):\n",
    "    model = genai.GenerativeModel(\"gemini-2.0-flash\")\n",
    "    query = build_prompt()\n",
    "\n",
    "    # Resize before sending\n",
    "    safe_img = resize_image(pil_image)\n",
    "\n",
    "    response = model.generate_content([query, safe_img])\n",
    "    return response.text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "15e105c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ali.zain\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:3442: DecompressionBombWarning: Image size (126346458 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📸 Resized image saved at c:\\Users\\ali.zain\\Desktop\\Content_Extraction\\research\\resized_page.png (450x2000)\n",
      "Extracted text from first page image:\n",
      "\n",
      "✅ JSON saved to gemini_response.json\n",
      "```json\n",
      "{\n",
      "  \"heading\": \"ADVANCING TECHNOLOGIES IN THE GEOTHERMAL ENERGY\\nSECTOR\",\n",
      "  \"description\": \"Welcome to Enhanced Geothermal Systems 2026, where\\nindustry leaders will examine the potential of next-generation\\ngeothermal power to transform the U.S. energy landscape.\\n\\nThe energy sector faces challenges with conventional\\ngeothermal systems, including limited hydrothermal\\nresources, drilling technologies, production declines, and\\nheat-to-electricity conversion limitations. This event will\\nspotlight enhanced geothermal systems, focusing on\\nhydraulic, chemical, thermal, and explosive stimulation\\nmethods that support innovation in energy production.\\n\\nJoin us to explore advanced solutions, connect with industry\\nexperts, and contribute to the future of geothermal energy\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "from pdf2image import convert_from_path\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# 1. Configure Gemini API\n",
    "genai.configure(api_key=\"AIzaSyDDoos-ITDh0hl694HB2um_iqdu36jREAw\")\n",
    "\n",
    "# 2. Extract pages of PDF as a PIL image\n",
    "def get_page_image(pdf_path, page_num):\n",
    "    images = convert_from_path(\n",
    "        pdf_path,\n",
    "        first_page=page_num,\n",
    "        last_page=page_num,\n",
    "        poppler_path=r\"C:\\Users\\ali.zain\\Desktop\\poppler-24.08.0\\Library\\bin\"\n",
    "    )\n",
    "    if images:\n",
    "        return images[0]  # Return PIL.Image.Image object\n",
    "    return None\n",
    "\n",
    "# 3. Prompt builder for event details\n",
    "\n",
    "# 5. Main\n",
    "if __name__ == \"__main__\":\n",
    "    pdf_path = r\"C:\\Users\\ali.zain\\Desktop\\Content_Extraction\\content.pdf\"\n",
    "\n",
    "    first_page_img = get_page_image(pdf_path, 2)\n",
    "\n",
    "    if first_page_img :\n",
    "        # Extract text from first page\n",
    "        first_page_text = ocr_with_gemini(\n",
    "            first_page_img\n",
    "            # \"From the provided form image, identify the industry option that is marked or checked. Return only the industry name (e.g., 'Clean Energy').\"\n",
    "        )\n",
    "        print(\"Extracted text from first page image:\\n\")\n",
    "        \n",
    "        # Save output JSON\n",
    "        with open(\"Page_home.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(first_page_text)\n",
    "\n",
    "        print(\"✅ JSON saved to gemini_response.json\")\n",
    "        print(first_page_text)\n",
    "    # else:\n",
    "    #     print(\"❌ Could not extract images from PDF.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "ba54141b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Payload saved to C:\\Users\\ali.zain\\Desktop\\Content_Extraction\\research\\Page_home_payload.json\n",
      "Status Code: 200\n",
      "Response JSON: [{'id': 1, 'option': 'heading', 'value': 'ADVANCING TECHNOLOGIES IN THE GEOTHERMAL ENERGY\\nSECTOR', 'label': 'Heading', 'createdAt': '2025-08-25T10:48:28.040Z', 'updatedAt': '2025-08-25T10:48:28.040Z'}, {'id': 2, 'option': 'paragraph', 'value': '<p>Welcome to Enhanced Geothermal Systems 2026, where<br>industry leaders will examine the potential of next-generation<br>geothermal power to transform the U.S. energy landscape.</p><p>The energy sector faces challenges with conventional<br>geothermal systems, including limited hydrothermal<br>resources, drilling technologies, production declines, and<br>heat-to-electricity conversion limitations. This event will<br>spotlight enhanced geothermal systems, focusing on<br>hydraulic, chemical, thermal, and explosive stimulation<br>methods that support innovation in energy production.</p><p>Join us to explore advanced solutions, connect with industry<br>experts, and contribute to the future of geothermal energy</p>', 'label': 'Paragraph', 'createdAt': '2025-08-25T10:48:28.040Z', 'updatedAt': '2025-08-25T10:48:28.040Z'}, {'id': 3, 'option': 'Video', 'value': '<figure class=\"media\"><oembed url=\"https://player.vimeo.com/video/236701630\"></oembed></figure>', 'label': 'Video Link', 'createdAt': '2025-08-25T10:48:28.040Z', 'updatedAt': '2025-08-25T10:48:28.040Z'}]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import requests\n",
    "\n",
    "# Path to your JSON file\n",
    "input_file = r\"C:\\Users\\ali.zain\\Desktop\\Content_Extraction\\research\\Page_home.json\"\n",
    "\n",
    "# Read file as text\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read().strip()\n",
    "\n",
    "# Remove markdown fences if present\n",
    "if raw_text.startswith(\"```\"):\n",
    "    raw_text = raw_text.strip(\"`\")\n",
    "    if raw_text.lower().startswith(\"json\"):\n",
    "        raw_text = raw_text[4:].strip()\n",
    "\n",
    "# Load as JSON\n",
    "data = json.loads(raw_text)\n",
    "\n",
    "# Extract values\n",
    "heading = data.get(\"heading\", \"\")\n",
    "description = data.get(\"description\", \"\")\n",
    "\n",
    "# Keep formatting:\n",
    "# - double newlines → new paragraphs\n",
    "# - single newline → line breaks\n",
    "paragraphs = description.split(\"\\n\\n\")\n",
    "\n",
    "description_html = \"\".join(\n",
    "    f\"<p>{p_clean}</p>\"\n",
    "    for p in paragraphs if (p_clean := p.replace(\"\\n\", \"<br>\").strip())\n",
    ")\n",
    "\n",
    "# Example video embed\n",
    "video_html = '<figure class=\"media\"><oembed url=\"https://player.vimeo.com/video/236701630\"></oembed></figure>'\n",
    "\n",
    "# Build payload\n",
    "payload = {\n",
    "    \"options\": [\n",
    "        {\n",
    "            \"id\": 1,\n",
    "            \"option\": \"heading\",\n",
    "            \"value\": heading,\n",
    "            \"label\": \"Heading\"\n",
    "        },\n",
    "        {\n",
    "            \"id\": 2,\n",
    "            \"option\": \"paragraph\",\n",
    "            \"value\": description_html,\n",
    "            \"label\": \"Paragraph\"\n",
    "        },\n",
    "        {\n",
    "            \"id\": 3,\n",
    "            \"option\": \"Video\",\n",
    "            \"value\": video_html,\n",
    "            \"label\": \"Video Link\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Save payload\n",
    "output_file = os.path.splitext(input_file)[0] + \"_payload.json\"\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(payload, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"✅ Payload saved to {output_file}\")\n",
    "\n",
    "# --- Post request (optional) ---\n",
    "url = \"https://ai-demo.genetechz.com/api/home-page\"\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "response = requests.post(url, headers=headers, data=json.dumps(payload))\n",
    "\n",
    "print(\"Status Code:\", response.status_code)\n",
    "try:\n",
    "    print(\"Response JSON:\", response.json())\n",
    "except:\n",
    "    print(\"Response Text:\", response.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2122d6f",
   "metadata": {},
   "source": [
    "# Key Points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "dbee00ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to output.json\n"
     ]
    }
   ],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "import json\n",
    "\n",
    "# Load PDF and extract fields\n",
    "reader = PdfReader(r\"C:\\Users\\ali.zain\\Desktop\\Content_Extraction\\content.pdf\")\n",
    "fields = reader.get_fields()\n",
    "\n",
    "# Filter fields that start with \"Text\" and have numeric suffix\n",
    "text_fields = {}\n",
    "for name, data in fields.items():\n",
    "    if name.startswith(\"Text\"):\n",
    "        try:\n",
    "            num = int(\"\".join(filter(str.isdigit, name)))\n",
    "            text_fields[num] = data.get(\"/V\")\n",
    "        except ValueError:\n",
    "            pass  # skip if not a valid number\n",
    "\n",
    "results = []\n",
    "\n",
    "# Loop through expected range\n",
    "for i in range(19, 31):\n",
    "    value = text_fields.get(i, None)\n",
    "    if i % 2 == 1:  # odd -> Title\n",
    "        current_item = {\"Title\": value, \"Description\": None}\n",
    "        results.append(current_item)\n",
    "    else:  # even -> Description\n",
    "        if results:  # assign description to last item\n",
    "            results[-1][\"Description\"] = value\n",
    "\n",
    "# Wrap results inside \"key_topics\"\n",
    "output = {\"key_topics\": results}\n",
    "\n",
    "# Save to JSON file\n",
    "with open(\"output.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(output, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"Saved to output.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "fddd0596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating ID 1\n",
      "Title: Evaluating the economic impact of geothermal energy projects across the US\n",
      "Status Code: 200\n",
      "Response: {\"message\":\"Key Topics Updated\"}\n",
      "--------------------------------------------------\n",
      "Updating ID 2\n",
      "Title: Key technical aspects and core designs for geothermal plant operations\n",
      "Status Code: 200\n",
      "Response: {\"message\":\"Key Topics Updated\"}\n",
      "--------------------------------------------------\n",
      "Updating ID 3\n",
      "Title: Latest geothermal regulatory updates on frameworks, permits, and incentives\n",
      "Status Code: 200\n",
      "Response: {\"message\":\"Key Topics Updated\"}\n",
      "--------------------------------------------------\n",
      "Updating ID 4\n",
      "Title: Advanced EGS technologies for resource optimization and energy production \n",
      "Status Code: 200\n",
      "Response: {\"message\":\"Key Topics Updated\"}\n",
      "--------------------------------------------------\n",
      "Updating ID 5\n",
      "Title: Innovative ways to integrate geothermal power plants with the power grid\n",
      "Status Code: 200\n",
      "Response: {\"message\":\"Key Topics Updated\"}\n",
      "--------------------------------------------------\n",
      "Updating ID 6\n",
      "Title: In-depth case studies from leading geothermal experts and policymakers\n",
      "Status Code: 200\n",
      "Response: {\"message\":\"Key Topics Updated\"}\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# API base URL for updates\n",
    "base_url = \"https://ai-demo.genetechz.com/api/key-topics/update\"\n",
    "\n",
    "# Payload with new data\n",
    "with open(\"output.json\", \"r\") as f:\n",
    "    payload = json.load(f)\n",
    "\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "# Loop through each topic and update by ID (1–6)\n",
    "for i, topic in enumerate(payload[\"key_topics\"], start=1):\n",
    "    url = f\"{base_url}/{i}\"   # e.g. /update/1, /update/2 ...\n",
    "    response = requests.post(url, json=topic, headers=headers)\n",
    "\n",
    "    print(f\"Updating ID {i}\")\n",
    "    print(\"Title:\", topic[\"Title\"])\n",
    "    print(\"Status Code:\", response.status_code)\n",
    "    print(\"Response:\", response.text)\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c560a8",
   "metadata": {},
   "source": [
    "# Statistics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "d976389a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt():\n",
    "    return f\"\"\"\n",
    "As a data extraction task, meticulously examine the provided image (original and cropped segments). The objective is to precisely identify the count or value associated with the following specific metrics displayed within the visual:\n",
    "Total Industry Topics\n",
    "Number of Networking Events\n",
    "Quantity of Leading Experts\n",
    "Number of Q&A Sessions\n",
    "Output the extracted data points clearly in json format \n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "6d18bd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import google.generativeai as genai\n",
    "\n",
    "def resize_image(pil_image, max_size=2000, save_path=\"resized_page.png\"):\n",
    "    \"\"\"Resize image to max_size while keeping aspect ratio. Save for inspection.\"\"\"\n",
    "    width, height = pil_image.size\n",
    "    if max(width, height) > max_size:\n",
    "        if width > height:\n",
    "            new_width = max_size\n",
    "            new_height = int(height * (max_size / width))\n",
    "        else:\n",
    "            new_height = max_size\n",
    "            new_width = int(width * (max_size / height))\n",
    "        pil_image = pil_image.resize((new_width, new_height), Image.LANCZOS)\n",
    "    # Save to disk so you can verify what Gemini sees\n",
    "    pil_image.save(save_path)\n",
    "    print(f\"📸 Resized image saved at {os.path.abspath(save_path)} ({pil_image.size[0]}x{pil_image.size[1]})\")\n",
    "    return pil_image\n",
    "\n",
    "def ocr_with_gemini(pil_image):\n",
    "    model = genai.GenerativeModel(\"gemma-3-4b-it\")\n",
    "    query = build_prompt()\n",
    "\n",
    "    # Resize before sending\n",
    "    safe_img = resize_image(pil_image)\n",
    "\n",
    "    response = model.generate_content([query, safe_img])\n",
    "    return response.text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "5eedce1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📸 Resized image saved at c:\\Users\\ali.zain\\Desktop\\Content_Extraction\\research\\resized_page.png (450x2000)\n",
      "Extracted text from first page image:\n",
      "\n",
      "✅ JSON saved to gemini_response.json\n",
      "```json\n",
      "{\n",
      "  \"Total Industry Topics\": \"100+\",\n",
      "  \"Number of Networking Events\": \"8+\",\n",
      "  \"Quantity of Leading Experts\": \"50+\",\n",
      "  \"Number of Q&A Sessions\": \"20+\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "from pdf2image import convert_from_path\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# 1. Configure Gemini API\n",
    "genai.configure(api_key=\"AIzaSyDDoos-ITDh0hl694HB2um_iqdu36jREAw\")\n",
    "\n",
    "# 2. Extract pages of PDF as a PIL image\n",
    "def get_page_image(pdf_path, page_num):\n",
    "    images = convert_from_path(\n",
    "        pdf_path,\n",
    "        first_page=page_num,\n",
    "        last_page=page_num,\n",
    "        poppler_path=r\"C:\\Users\\ali.zain\\Desktop\\poppler-24.08.0\\Library\\bin\"\n",
    "    )\n",
    "    if images:\n",
    "        return images[0]  # Return PIL.Image.Image object\n",
    "    return None\n",
    "\n",
    "# 3. Prompt builder for event details\n",
    "\n",
    "# 5. Main\n",
    "if __name__ == \"__main__\":\n",
    "    pdf_path = r\"C:\\Users\\ali.zain\\Desktop\\Content_Extraction\\content.pdf\"\n",
    "\n",
    "    first_page_img = get_page_image(pdf_path, 2)\n",
    "\n",
    "    if first_page_img :\n",
    "        # Extract text from first page\n",
    "        first_page_text = ocr_with_gemini(\n",
    "            first_page_img\n",
    "            # \"From the provided form image, identify the industry option that is marked or checked. Return only the industry name (e.g., 'Clean Energy').\"\n",
    "        )\n",
    "        print(\"Extracted text from first page image:\\n\")\n",
    "        \n",
    "        # Save output JSON\n",
    "        with open(\"Statistics.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(first_page_text)\n",
    "\n",
    "        print(\"✅ JSON saved to gemini_response.json\")\n",
    "        print(first_page_text)\n",
    "\n",
    "    # else:\n",
    "    #     print(\"❌ Could not extract images from PDF.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "f592ef8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Updated payload saved to: Statistics.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "file_path = \"Statistics.json\"\n",
    "\n",
    "# Step 1: Read raw file text\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read().strip()\n",
    "\n",
    "# Step 2: Remove wrapping triple quotes if present\n",
    "if raw_text.startswith(\"```json\"):\n",
    "    raw_text = raw_text[len(\"```json\"):].strip()\n",
    "if raw_text.endswith(\"```\"):\n",
    "    raw_text = raw_text[:-3].strip()\n",
    "\n",
    "# Step 3: Load cleaned JSON\n",
    "data = json.loads(raw_text)\n",
    "\n",
    "# Step 4: Transform into payload format\n",
    "payload = []\n",
    "for key, value in data.items():\n",
    "    figure = value.replace(\"+\", \"\")   # strip '+' for figure\n",
    "    caption = key.upper()             # uppercase caption\n",
    "    isplus = \"yes\" if \"+\" in value else \"no\"\n",
    "\n",
    "    payload.append({\n",
    "        \"figure\": figure,\n",
    "        \"caption\": caption,\n",
    "        \"isplus\": isplus\n",
    "    })\n",
    "\n",
    "# Step 5: Save back to same file (or new file if you prefer)\n",
    "with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(payload, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"✅ Updated payload saved to:\", file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "1163abe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request to https://ai-demo.genetechz.com/api/statistics/update/1\n",
      "Payload: {'figure': '100', 'caption': 'TOTAL INDUSTRY TOPICS', 'isplus': 'yes'}\n",
      "Status Code: 200\n",
      "Response: {'message': 'Statistics Updated'}\n",
      "--------------------------------------------------\n",
      "Request to https://ai-demo.genetechz.com/api/statistics/update/2\n",
      "Payload: {'figure': '8', 'caption': 'NUMBER OF NETWORKING EVENTS', 'isplus': 'yes'}\n",
      "Status Code: 200\n",
      "Response: {'message': 'Statistics Updated'}\n",
      "--------------------------------------------------\n",
      "Request to https://ai-demo.genetechz.com/api/statistics/update/3\n",
      "Payload: {'figure': '50', 'caption': 'QUANTITY OF LEADING EXPERTS', 'isplus': 'yes'}\n",
      "Status Code: 200\n",
      "Response: {'message': 'Statistics Updated'}\n",
      "--------------------------------------------------\n",
      "Request to https://ai-demo.genetechz.com/api/statistics/update/4\n",
      "Payload: {'figure': '20', 'caption': 'NUMBER OF Q&A SESSIONS', 'isplus': 'yes'}\n",
      "Status Code: 200\n",
      "Response: {'message': 'Statistics Updated'}\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Your API base URL\n",
    "base_url = \"https://ai-demo.genetechz.com/api/statistics/update/\"\n",
    "\n",
    "# The payload you provided\n",
    "with open(\"Statistics.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    payload = json.load(f)\n",
    "\n",
    "# Loop over payload and send POST requests\n",
    "for i, item in enumerate(payload, start=1):\n",
    "    url = f\"{base_url}{i}\"   # auto increment id in URL\n",
    "    response = requests.post(url, json=item)\n",
    "\n",
    "    print(f\"Request to {url}\")\n",
    "    print(\"Payload:\", item)\n",
    "    print(\"Status Code:\", response.status_code)\n",
    "    try:\n",
    "        print(\"Response:\", response.json())\n",
    "    except:\n",
    "        print(\"Response Text:\", response.text)\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc5c8d3",
   "metadata": {},
   "source": [
    "# Expert Speaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1b3df459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-generativeai in c:\\users\\ali.zain\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.8.5)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in c:\\users\\ali.zain\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-generativeai) (0.6.15)\n",
      "Requirement already satisfied: google-api-core in c:\\users\\ali.zain\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-generativeai) (2.25.1)\n",
      "Requirement already satisfied: google-api-python-client in c:\\users\\ali.zain\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-generativeai) (2.176.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in c:\\users\\ali.zain\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-generativeai) (2.40.3)\n",
      "Requirement already satisfied: protobuf in c:\\users\\ali.zain\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-generativeai) (5.29.5)\n",
      "Requirement already satisfied: pydantic in c:\\users\\ali.zain\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-generativeai) (2.11.7)\n",
      "Requirement already satisfied: tqdm in c:\\users\\ali.zain\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-generativeai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\ali.zain\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-generativeai) (4.14.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\ali.zain\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in c:\\users\\ali.zain\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-api-core->google-generativeai) (1.70.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in c:\\users\\ali.zain\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-api-core->google-generativeai) (2.32.4)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in c:\\users\\ali.zain\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.73.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in c:\\users\\ali.zain\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\ali.zain\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\ali.zain\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\ali.zain\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\ali.zain\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ali.zain\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ali.zain\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ali.zain\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.6.15)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\ali.zain\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
      "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in c:\\users\\ali.zain\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in c:\\users\\ali.zain\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\users\\ali.zain\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\ali.zain\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\ali.zain\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic->google-generativeai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\ali.zain\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic->google-generativeai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\ali.zain\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic->google-generativeai) (0.4.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\ali.zain\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm->google-generativeai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "bc0d55e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt():\n",
    "    return \"\"\"\n",
    "As a data extraction task, meticulously examine the provided image \n",
    "The objective is to precisely identify the value associated with the Expert Speakers within the visual:\n",
    "- Speaker name \n",
    "- Company name\n",
    "\n",
    "There are total 3 expert speakers and their company name  .\n",
    "write a proper name if there is any typo in the image.\n",
    "Output the extracted data points clearly in JSON format:\n",
    "\n",
    "{\n",
    "  \"expert_speakers\": [\n",
    "    {\n",
    "      \"name\": \"\",\n",
    "      \"company\": \"\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"\",\n",
    "      \"company\": \"\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"\",\n",
    "      \"company\": \"\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "41c39935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"expert_speakers\": [\n",
      "    {\n",
      "      \"name\": \"Agung Setyadi\",\n",
      "      \"company\": \"Geo Dipa Energ\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Karl Farrow\",\n",
      "      \"company\": \"CeraPhi Energy\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Mazda Irani\",\n",
      "      \"company\": \"Ashaw Energy\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import google.generativeai as genai\n",
    "import io\n",
    "\n",
    "# 1. Configure API key\n",
    "genai.configure(api_key=\"AIzaSyDDoos-ITDh0hl694HB2um_iqdu36jREAw\")\n",
    "\n",
    "# 2. Load the model\n",
    "model = genai.GenerativeModel(\"gemini-2.5-flash\")\n",
    "\n",
    "# 3. Open image and convert to bytes\n",
    "with Image.open(r\"C:\\Users\\ali.zain\\Desktop\\Content_Extraction\\research\\crop_image.png\") as img:\n",
    "    img_bytes = io.BytesIO()\n",
    "    img.save(img_bytes, format=\"PNG\")\n",
    "    img_bytes.seek(0)\n",
    "\n",
    "query=build_prompt()\n",
    "# 4. Ask Gemini with image + text prompt\n",
    "response = model.generate_content([\n",
    "    {\n",
    "        \"mime_type\": \"image/png\",\n",
    "        \"data\": img_bytes.read()\n",
    "    },\n",
    "    query\n",
    "])\n",
    "# 5. Print response\n",
    "print(response.text)\n",
    "with open(\"Expert_Speaker.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(response.text)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "b9a7dbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "file_path = r\"C:\\Users\\ali.zain\\Desktop\\Content_Extraction\\research\\Expert_Speaker.json\"\n",
    "# Step 1: Read raw file text\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read().strip()\n",
    "\n",
    "# Step 2: Remove wrapping triple quotes if present\n",
    "if raw_text.startswith(\"```json\"):\n",
    "    raw_text = raw_text[len(\"```json\"):].strip()\n",
    "if raw_text.endswith(\"```\"):\n",
    "    raw_text = raw_text[:-3].strip()\n",
    "\n",
    "# Step 3: Load cleaned JSON\n",
    "data = json.loads(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d598a439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://ai-demo.genetechz.com/api/expert-speakers/update/11\n",
      "Sending: {'name': 'Agung Setyadi', 'company': 'Geo Dipa Energ'}\n",
      "Status Code: 200\n",
      "Response: {\"message\":\"Expert Speakers Updated\"}\n",
      "--------------------------------------------------\n",
      "https://ai-demo.genetechz.com/api/expert-speakers/update/11/12\n",
      "Sending: {'name': 'Karl Farrow', 'company': 'CeraPhi Energy'}\n",
      "Status Code: 404\n",
      "Response: <!DOCTYPE html>\n",
      "<html lang=\"en\">\n",
      "<head>\n",
      "<meta charset=\"utf-8\">\n",
      "<title>Error</title>\n",
      "</head>\n",
      "<body>\n",
      "<pre>Cannot POST /expert-speakers/update/11/12</pre>\n",
      "</body>\n",
      "</html>\n",
      "\n",
      "--------------------------------------------------\n",
      "https://ai-demo.genetechz.com/api/expert-speakers/update/11/12/13\n",
      "Sending: {'name': 'Mazda Irani', 'company': 'Ashaw Energy'}\n",
      "Status Code: 404\n",
      "Response: <!DOCTYPE html>\n",
      "<html lang=\"en\">\n",
      "<head>\n",
      "<meta charset=\"utf-8\">\n",
      "<title>Error</title>\n",
      "</head>\n",
      "<body>\n",
      "<pre>Cannot POST /expert-speakers/update/11/12/13</pre>\n",
      "</body>\n",
      "</html>\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "# Your API endpoint\n",
    "\n",
    "\n",
    "# Loop through expert speakers and send POST request for each\n",
    "count=11\n",
    "for speaker in data[\"expert_speakers\"]:\n",
    "    url = \"https://ai-demo.genetechz.com/api/expert-speakers/update\"\n",
    "    payload = {\n",
    "        \"name\": speaker[\"name\"],\n",
    "        \"company\": speaker[\"company\"]\n",
    "    }\n",
    "    url = f\"{url}/{count}\"\n",
    "    count+=1\n",
    "    print(url)\n",
    "    response = requests.post(url, json=payload)\n",
    "\n",
    "    print(f\"Sending: {payload}\")\n",
    "    print(f\"Status Code: {response.status_code}\")\n",
    "    print(f\"Response: {response.text}\")\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92188b3",
   "metadata": {},
   "source": [
    "# Crop Section From PDF For Past Attendees AndExpert Speaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "a1c850a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdf2image import convert_from_path\n",
    "from PIL import Image\n",
    "\n",
    "def get_page_image(pdf_path, page_num):\n",
    "    images = convert_from_path(\n",
    "        pdf_path,\n",
    "        first_page=page_num,\n",
    "        last_page=page_num,\n",
    "        poppler_path=r\"C:\\Users\\ali.zain\\Desktop\\poppler-24.08.0\\Library\\bin\"\n",
    "    )\n",
    "    if images:\n",
    "        return images[0]  # Return PIL.Image.Image object\n",
    "    return None\n",
    "    \n",
    "file_path = r\"C:\\Users\\ali.zain\\Desktop\\Content_Extraction\\content.pdf\"\n",
    "img = get_page_image(file_path, 2)\n",
    "\n",
    "if img:\n",
    "# Example coordinates (left, top, right, bottom)\n",
    "    crop_box = (886, 11100, 3250, 12347)\n",
    "    cropped = img.crop(crop_box)\n",
    "\n",
    "    cropped.show()\n",
    "cropped.save(r\"C:\\Users\\ali.zain\\Desktop\\Content_Extraction\\research\\crop_image.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec5c343",
   "metadata": {},
   "source": [
    "# Past Attendees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "f6c2fd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt():\n",
    "    return \"\"\"\n",
    "    You are given an image that contains different sections, including \"Expert Speakers\" on the left and \"Past Attendees\" on the right.\n",
    "\n",
    "Your task is to carefully analyze the image and extract the names listed under the \"Past Attendees\" section only.\n",
    "\n",
    "There are exactly  past attendees in this section.\n",
    "\n",
    "Ignore other sections such as \"Expert Speakers\" or registration information.\n",
    "\n",
    "Present the extracted names in a structured JSON format as follows:\n",
    "\n",
    "{\n",
    "  \"Past Attendees\": [\n",
    "    { \"name\": \"Attendee 1\" },\n",
    "    { \"name\": \"Attendee 2\" },\n",
    "    { \"name\": \"Attendee 3\" },\n",
    "    { \"name\": \"Attendee 4\" },\n",
    "    { \"name\": \"Attendee 5\" },\n",
    "    { \"name\": \"Attendee 6\" },\n",
    "    { \"name\": \"Attendee 7\" },\n",
    "    { \"name\": \"Attendee 8\" },\n",
    "    { \"name\": \"Attendee 9\" }\n",
    "  ]\n",
    "}\n",
    "\n",
    "Ensure the names are captured exactly as they appear in the image without alterations.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "7726762f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"Past Attendees\": [\n",
      "    { \"name\": \"Ali\" },\n",
      "    { \"name\": \"Pioneer Natural Resources\" },\n",
      "    { \"name\": \"CG Thermal\" },\n",
      "    { \"name\": \"Chevron\" },\n",
      "    { \"name\": \"ExxonMobil\" },\n",
      "    { \"name\": \"TotalEnergies\" },\n",
      "    { \"name\": \"Technip Energies\" },\n",
      "    { \"name\": \"Zain\" },\n",
      "    { \"name\": \"SLB\" }\n",
      "  ]\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import google.generativeai as genai\n",
    "import io\n",
    "\n",
    "# 1. Configure API key\n",
    "genai.configure(api_key=\"AIzaSyDDoos-ITDh0hl694HB2um_iqdu36jREAw\")\n",
    "\n",
    "# 2. Load the model\n",
    "model = genai.GenerativeModel(\"gemini-2.5-flash\")\n",
    "\n",
    "# 3. Open image and convert to bytes\n",
    "with Image.open(r\"C:\\Users\\ali.zain\\Desktop\\Content_Extraction\\research\\crop_image.jpg\") as img:\n",
    "    img_bytes = io.BytesIO()\n",
    "    img.save(img_bytes, format=\"PNG\")\n",
    "    img_bytes.seek(0)\n",
    "\n",
    "query=build_prompt()\n",
    "# 4. Ask Gemini with image + text prompt\n",
    "response = model.generate_content([\n",
    "    {\n",
    "        \"mime_type\": \"image/png\",\n",
    "        \"data\": img_bytes.read()\n",
    "    },\n",
    "    query\n",
    "])\n",
    "# 5. Print response\n",
    "print(response.text)\n",
    "with open(\"past_attendees.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "16f6a0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "file_path = r\"C:\\Users\\ali.zain\\Desktop\\Content_Extraction\\research\\past_attendees.json\"\n",
    "# Step 1: Read raw file text\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read().strip()\n",
    "\n",
    "# Step 2: Remove wrapping triple quotes if present\n",
    "if raw_text.startswith(\"```json\"):\n",
    "    raw_text = raw_text[len(\"```json\"):].strip()\n",
    "if raw_text.endswith(\"```\"):\n",
    "    raw_text = raw_text[:-3].strip()\n",
    "\n",
    "# Step 3: Load cleaned JSON\n",
    "data = json.loads(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "b74f34ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending: {'attendees': 'Ali'}\n",
      "Status Code: 200\n",
      "Response: {\"msg\":\"Past Attendees Added\"}\n",
      "--------------------------------------------------\n",
      "Sending: {'attendees': 'Pioneer Natural Resources'}\n",
      "Status Code: 200\n",
      "Response: {\"msg\":\"Past Attendees Added\"}\n",
      "--------------------------------------------------\n",
      "Sending: {'attendees': 'CG Thermal'}\n",
      "Status Code: 200\n",
      "Response: {\"msg\":\"Past Attendees Added\"}\n",
      "--------------------------------------------------\n",
      "Sending: {'attendees': 'Chevron'}\n",
      "Status Code: 200\n",
      "Response: {\"msg\":\"Past Attendees Added\"}\n",
      "--------------------------------------------------\n",
      "Sending: {'attendees': 'ExxonMobil'}\n",
      "Status Code: 200\n",
      "Response: {\"msg\":\"Past Attendees Added\"}\n",
      "--------------------------------------------------\n",
      "Sending: {'attendees': 'TotalEnergies'}\n",
      "Status Code: 200\n",
      "Response: {\"msg\":\"Past Attendees Added\"}\n",
      "--------------------------------------------------\n",
      "Sending: {'attendees': 'Technip Energies'}\n",
      "Status Code: 200\n",
      "Response: {\"msg\":\"Past Attendees Added\"}\n",
      "--------------------------------------------------\n",
      "Sending: {'attendees': 'Zain'}\n",
      "Status Code: 200\n",
      "Response: {\"msg\":\"Past Attendees Added\"}\n",
      "--------------------------------------------------\n",
      "Sending: {'attendees': 'SLB'}\n",
      "Status Code: 200\n",
      "Response: {\"msg\":\"Past Attendees Added\"}\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "# Your API endpoint\n",
    "url = \"https://ai-demo.genetechz.com/api/past-attendences\"\n",
    "\n",
    "\n",
    "# Loop through expert speakers and send POST request for each\n",
    "for speaker in data[\"Past Attendees\"]:\n",
    "    payload = {\n",
    "        \"attendees\": speaker[\"name\"],\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, json=payload)\n",
    "\n",
    "    print(f\"Sending: {payload}\")\n",
    "    print(f\"Status Code: {response.status_code}\")\n",
    "    print(f\"Response: {response.text}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5ce1f4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fea25e42",
   "metadata": {},
   "source": [
    "# Testimonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a686f03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdf2image import convert_from_path\n",
    "from PIL import Image\n",
    "\n",
    "def get_page_image(pdf_path, page_num):\n",
    "    images = convert_from_path(\n",
    "    pdf_path,\n",
    "    first_page=page_num,\n",
    "    last_page=page_num,\n",
    "    poppler_path=r\"C:\\Users\\ali.zain\\Desktop\\poppler-24.08.0\\Library\\bin\"\n",
    "    )\n",
    "    if images:\n",
    "        return images[0]\n",
    "    return None\n",
    "\n",
    "# Load page\n",
    "file=r\"C:\\Users\\ali.zain\\Desktop\\Content_Extraction\\content.pdf\"\n",
    "img = get_page_image(file, 2)\n",
    "\n",
    "if img:\n",
    "    crop_box = (974, 13078, 4347, 17505)\n",
    "    cropped = img.crop(crop_box)\n",
    "cropped.save(r\"C:\\Users\\ali.zain\\Desktop\\Content_Extraction\\research\\Testimonial.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "e0c4643b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt():\n",
    "    return \"\"\"\n",
    "    You are given an image that contains multiple testimonials. Each testimonial consists of three elements:\n",
    "\n",
    "The testimonial text (inside quotes).\n",
    "\n",
    "The name of the person.\n",
    "\n",
    "The company/organization name (immediately below the name).\n",
    "\n",
    "Your task:\n",
    "\n",
    "Extract all testimonials in the exact order specified below.\n",
    "\n",
    "The order of extraction is strictly top-right first → then middle section → then bottom-left last.\n",
    "\n",
    "Do not shuffle, reorder, or skip any testimonial. Follow the sequence exactly as it appears by position.\n",
    "\n",
    "Output format: Return the results as a JSON array with the following structure:\n",
    "\n",
    "{\n",
    "  \"testimonial\": [\n",
    "    { \"name\": \"Attendee 1\", \"company\": \"Company 1\", \"text\": \"Testimonial text 1\" },\n",
    "    { \"name\": \"Attendee 2\", \"company\": \"Company 2\", \"text\": \"Testimonial text 2\" },\n",
    "    { \"name\": \"Attendee 3\", \"company\": \"Company 3\", \"text\": \"Testimonial text 3\" },\n",
    "    { \"name\": \"Attendee 4\", \"company\": \"Company 4\", \"text\": \"Testimonial text 4\" },\n",
    "    { \"name\": \"Attendee 5\", \"company\": \"Company 5\", \"text\": \"Testimonial text 5\" },\n",
    "    { \"name\": \"Attendee 6\", \"company\": \"Company 6\", \"text\": \"Testimonial text 6\" }\n",
    "  ]\n",
    "}\n",
    "Important:\n",
    "Preserve the exact spelling, formatting, and wording of names and companies as shown in the image.\n",
    "Do not modify or normalize text.\n",
    "Ensure every testimonial is included in the correct order.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050197f2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "3eb38deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"testimonial\": [\n",
      "    {\n",
      "      \"name\": \"Jennifer Zwarch\",\n",
      "      \"company\": \"Alberta Energy Regulator\",\n",
      "      \"text\": \"Incredible learnings into various technologies and the state of the industry.\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Don Mack\",\n",
      "      \"company\": \"Siemens Industry, Inc.\",\n",
      "      \"text\": \"Great insights into the industry from speakers and highly engaging panel sessions.\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"John Agele\",\n",
      "      \"company\": \"Weatherford\",\n",
      "      \"text\": \"Very informative event; enjoyed discovering different approaches and perspectives.\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Josh Brownlow\",\n",
      "      \"company\": \"Pioneer Natural Resources\",\n",
      "      \"text\": \"Excellent chance to engage with current industry leaders and experts.\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Pater Vaet\",\n",
      "      \"company\": \"Go2Lithium\",\n",
      "      \"text\": \"A remarkable event addressing a range of key industry issues.\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Michelle Mashava\",\n",
      "      \"company\": \"E3 Lithium\",\n",
      "      \"text\": \"Highly knowledgeable speakers sharing diverse insights and detailed analysis.\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import google.generativeai as genai\n",
    "import io\n",
    "\n",
    "# 1. Configure API key\n",
    "genai.configure(api_key=\"AIzaSyDDoos-ITDh0hl694HB2um_iqdu36jREAw\")\n",
    "\n",
    "# 2. Load the model\n",
    "model = genai.GenerativeModel(\"gemma-3-4b-it\")\n",
    "\n",
    "# 3. Open image and convert to bytes\n",
    "with Image.open(r\"C:\\Users\\ali.zain\\Desktop\\Content_Extraction\\research\\Testimonial.png\") as img:\n",
    "    img_bytes = io.BytesIO()\n",
    "    img.save(img_bytes, format=\"PNG\")\n",
    "    img_bytes.seek(0)\n",
    "\n",
    "query=build_prompt()\n",
    "# 4. Ask Gemini with image + text prompt\n",
    "response = model.generate_content([\n",
    "    {\n",
    "        \"mime_type\": \"image/png\",\n",
    "        \"data\": img_bytes.read()\n",
    "    },\n",
    "    query\n",
    "])\n",
    "# 5. Print response\n",
    "print(response.text)\n",
    "with open(\"Testimonial.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "88337061",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "file_path = r\"C:\\Users\\ali.zain\\Desktop\\Content_Extraction\\research\\Testimonial.json\"\n",
    "# Step 1: Read raw file text\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read().strip()\n",
    "\n",
    "# Step 2: Remove wrapping triple quotes if present\n",
    "if raw_text.startswith(\"```json\"):\n",
    "    raw_text = raw_text[len(\"```json\"):].strip()\n",
    "if raw_text.endswith(\"```\"):\n",
    "    raw_text = raw_text[:-3].strip()\n",
    "\n",
    "# Step 3: Load cleaned JSON\n",
    "data = json.loads(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "85a15253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://ai-demo.genetechz.com/api/testimonials/update/1\n",
      "Sending: {'name': 'Jennifer Zwarch', 'company': 'Alberta Energy Regulator', 'testimonial': 'Incredible learnings into various technologies and the state of the industry.', 'title': 'Lorem', 'ishome': '1'}\n",
      "Status Code: 200\n",
      "Response: {\"message\":\"Testimonials Updated\"}\n",
      "--------------------------------------------------\n",
      "https://ai-demo.genetechz.com/api/testimonials/update/2\n",
      "Sending: {'name': 'Don Mack', 'company': 'Siemens Industry, Inc.', 'testimonial': 'Great insights into the industry from speakers and highly engaging panel sessions.', 'title': 'Lorem', 'ishome': '1'}\n",
      "Status Code: 200\n",
      "Response: {\"message\":\"Testimonials Updated\"}\n",
      "--------------------------------------------------\n",
      "https://ai-demo.genetechz.com/api/testimonials/update/3\n",
      "Sending: {'name': 'John Agele', 'company': 'Weatherford', 'testimonial': 'Very informative event; enjoyed discovering different approaches and perspectives.', 'title': 'Lorem', 'ishome': '1'}\n",
      "Status Code: 200\n",
      "Response: {\"message\":\"Testimonials Updated\"}\n",
      "--------------------------------------------------\n",
      "https://ai-demo.genetechz.com/api/testimonials/update/4\n",
      "Sending: {'name': 'Josh Brownlow', 'company': 'Pioneer Natural Resources', 'testimonial': 'Excellent chance to engage with current industry leaders and experts.', 'title': 'Lorem', 'ishome': '1'}\n",
      "Status Code: 200\n",
      "Response: {\"message\":\"Testimonials Updated\"}\n",
      "--------------------------------------------------\n",
      "https://ai-demo.genetechz.com/api/testimonials/update/5\n",
      "Sending: {'name': 'Pater Vaet', 'company': 'Go2Lithium', 'testimonial': 'A remarkable event addressing a range of key industry issues.', 'title': 'Lorem', 'ishome': '1'}\n",
      "Status Code: 200\n",
      "Response: {\"message\":\"Testimonials Updated\"}\n",
      "--------------------------------------------------\n",
      "https://ai-demo.genetechz.com/api/testimonials/update/6\n",
      "Sending: {'name': 'Michelle Mashava', 'company': 'E3 Lithium', 'testimonial': 'Highly knowledgeable speakers sharing diverse insights and detailed analysis.', 'title': 'Lorem', 'ishome': '1'}\n",
      "Status Code: 200\n",
      "Response: {\"message\":\"Testimonials Updated\"}\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "# Your API endpoint\n",
    "\n",
    "count=1\n",
    "# Loop through expert speakers and send POST request for each\n",
    "for speaker in data[\"testimonial\"]:\n",
    "    url = \"https://ai-demo.genetechz.com/api/testimonials/update\"\n",
    "\n",
    "    payload = {\n",
    "        \"name\": speaker[\"name\"],\n",
    "        \"company\": speaker[\"company\"],\n",
    "        \"testimonial\": speaker[\"text\"],\n",
    "        \"title\": speaker.get(\"title\", \"Lorem\"),   # keep optional if not always available\n",
    "        \"ishome\": speaker.get(\"ishome\", \"1\")\n",
    "    }\n",
    "    url+=f\"/{count}\"\n",
    "    print(url)\n",
    "    response = requests.post(url, json=payload)\n",
    "    count+=1\n",
    "\n",
    "    print(f\"Sending: {payload}\")\n",
    "    print(f\"Status Code: {response.status_code}\")\n",
    "    print(f\"Response: {response.text}\")\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a6340c",
   "metadata": {},
   "source": [
    "# related events in the series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "a71e5403",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ali.zain\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:3442: DecompressionBombWarning: Image size (126346458 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from pdf2image import convert_from_path\n",
    "from PIL import Image\n",
    "\n",
    "def get_page_image(pdf_path, page_num):\n",
    "    images = convert_from_path(\n",
    "    pdf_path,\n",
    "    first_page=page_num,\n",
    "    last_page=page_num,\n",
    "    poppler_path=r\"C:\\Users\\ali.zain\\Desktop\\poppler-24.08.0\\Library\\bin\"\n",
    "    )\n",
    "    if images:\n",
    "        return images[0]\n",
    "    return None\n",
    "\n",
    "# Load page\n",
    "file=r\"C:\\Users\\ali.zain\\Desktop\\Content_Extraction\\content.pdf\"\n",
    "img = get_page_image(file, 2)\n",
    "\n",
    "if img:\n",
    "    crop_box = (955, 20260, 4413, 21854)\n",
    "    cropped = img.crop(crop_box)\n",
    "\n",
    "cropped.show()\n",
    "cropped.save(r\"C:\\Users\\ali.zain\\Desktop\\Content_Extraction\\research\\RelatedEvents.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07914982",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt():\n",
    "    return \"\"\"\n",
    "    You are an expert at extracting structured data from images. Analyze the provided image, which shows a section of upcoming events displayed as cards. There are multiple event cards visible.\n",
    "For each event card, extract the following information and output it as a JSON array of objects. Each object should represent one event and include exactly these keys:\n",
    "\n",
    "\"eventname\": The full name of the event, including any year or edition (e.g., \"Direct Lithium Extraction USA 2025\"). If no full name is visible, use the abbreviation or code as a fallback.\n",
    "\"eventlocation\": The location in the format \"City, State, Country\" (e.g., \"Orange County, California, USA\"). If incomplete, use what's available.\n",
    "\"eventlink\": If a hyperlink or URL is visible or inferable from the image, include it; otherwise, set to null.\n",
    "\"eventdate\": The date in the format \"MM DD - DD, YYYY\" if specific days are given, or a more general format like \"December 1 - 2,2025\" if that's what's shown. Include any ordinal indicators like \"1st\" or \"OR\" alternatives if present, but prioritize the most complete date.\n",
    "\"image\": If an image path or filename is visible or referenced in the card, include it; otherwise, set to null.\n",
    "\"hoverimage\": If a hover image path or reference is visible, include it; otherwise, set to null.\n",
    "\n",
    "Output only the JSON array, nothing else. Ensure the JSON is valid and well-formatted. If any field cannot be determined, set it to null. If there are multiple events, list them in the order they appear from left to right.\n",
    "data = [\n",
    "#   {\n",
    "#     \"eventname\": ,\n",
    "#     \"eventlocation\": \",\n",
    "#     \"eventlink\": \"\",\n",
    "#     \"eventdate\": ,\n",
    "#     \"image\": None,\n",
    "#     \"hoverimage\": None\n",
    "#   },\n",
    "#   {\n",
    "#     \"eventname\":,\n",
    "#     \"eventlocation\": ,\n",
    "#     \"eventlink\": \" \",\n",
    "#     \"eventdate\": ,\n",
    "#     \"image\": None,\n",
    "#     \"hoverimage\": None\n",
    "#   },\n",
    "#   {\n",
    "#     \"eventname\": ,\n",
    "#     \"eventlocation\": ,\n",
    "#     \"eventlink\": \"\",\n",
    "#     \"eventdate\": ,\n",
    "#     \"image\": None,\n",
    "#     \"hoverimage\": None\n",
    "#   }\n",
    "# ]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "6393e8d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "[\n",
      "  {\n",
      "    \"eventname\": \"Direct Lithium Extraction USA 2025\",\n",
      "    \"eventlocation\": \"Orange County, California, USA\",\n",
      "    \"eventlink\": null,\n",
      "    \"eventdate\": \"December 1st-2nd, 2025\",\n",
      "    \"image\": null,\n",
      "    \"hoverimage\": null\n",
      "  },\n",
      "  {\n",
      "    \"eventname\": \"Reservoir Simulation 2025\",\n",
      "    \"eventlocation\": \"Houston, Texas, USA\",\n",
      "    \"eventlink\": null,\n",
      "    \"eventdate\": \"December 3rd-4th, 2025\",\n",
      "    \"image\": null,\n",
      "    \"hoverimage\": null\n",
      "  },\n",
      "  {\n",
      "    \"eventname\": \"Frac Sand USA 2026\",\n",
      "    \"eventlocation\": \"Houston, Texas, USA\",\n",
      "    \"eventlink\": null,\n",
      "    \"eventdate\": \"December 11th-12th, 2025\",\n",
      "    \"image\": null,\n",
      "    \"hoverimage\": null\n",
      "  }\n",
      "]\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import google.generativeai as genai\n",
    "import io\n",
    "\n",
    "# 1. Configure API key\n",
    "genai.configure(api_key=\"AIzaSyDDoos-ITDh0hl694HB2um_iqdu36jREAw\")\n",
    "\n",
    "# 2. Load the model\n",
    "model = genai.GenerativeModel(\"gemma-3-4b-it\")\n",
    "\n",
    "# 3. Open image and convert to bytes\n",
    "with Image.open(r\"C:\\Users\\ali.zain\\Desktop\\Content_Extraction\\research\\RelatedEvents.png\") as img:\n",
    "    img_bytes = io.BytesIO()\n",
    "    img.save(img_bytes, format=\"PNG\")\n",
    "    img_bytes.seek(0)\n",
    "\n",
    "query=build_prompt()\n",
    "# 4. Ask Gemini with image + text prompt\n",
    "response = model.generate_content([\n",
    "    {\n",
    "        \"mime_type\": \"image/png\",\n",
    "        \"data\": img_bytes.read()\n",
    "    },\n",
    "    query\n",
    "])\n",
    "# 5. Print response\n",
    "print(response.text)\n",
    "with open(\"RelatedEvents.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "3c41b997",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "file_path = r\"C:\\Users\\ali.zain\\Desktop\\Content_Extraction\\research\\RelatedEvents.json\"\n",
    "# Step 1: Read raw file text\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read().strip()\n",
    "\n",
    "# Step 2: Remove wrapping triple quotes if present\n",
    "if raw_text.startswith(\"```json\"):\n",
    "    raw_text = raw_text[len(\"```json\"):].strip()\n",
    "if raw_text.endswith(\"```\"):\n",
    "    raw_text = raw_text[:-3].strip()\n",
    "\n",
    "# Step 3: Load cleaned JSON\n",
    "data = json.loads(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "83c9f187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending request to: https://ai-demo.genetechz.com/api/upcoming-events/update/4\n",
      "✅ Success (Event 4)\n",
      "Payload: {'eventname': 'Direct Lithium Extraction USA 2025', 'eventlocation': 'Orange County, California, USA', 'eventlink': None, 'eventdate': 'December 1st-2nd, 2025', 'image': None, 'hoverimage': None}\n",
      "Response: {\"message\":\"Upcoming Events Updated\"}\n",
      "--------------------------------------------------\n",
      "Sending request to: https://ai-demo.genetechz.com/api/upcoming-events/update/5\n",
      "✅ Success (Event 5)\n",
      "Payload: {'eventname': 'Reservoir Simulation 2025', 'eventlocation': 'Houston, Texas, USA', 'eventlink': None, 'eventdate': 'December 3rd-4th, 2025', 'image': None, 'hoverimage': None}\n",
      "Response: {\"message\":\"Upcoming Events Updated\"}\n",
      "--------------------------------------------------\n",
      "Sending request to: https://ai-demo.genetechz.com/api/upcoming-events/update/6\n",
      "✅ Success (Event 6)\n",
      "Payload: {'eventname': 'Frac Sand USA 2026', 'eventlocation': 'Houston, Texas, USA', 'eventlink': None, 'eventdate': 'December 11th-12th, 2025', 'image': None, 'hoverimage': None}\n",
      "Response: {\"message\":\"Upcoming Events Updated\"}\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "count = 4\n",
    "for speaker in data:\n",
    "    url = f\"https://ai-demo.genetechz.com/api/upcoming-events/update/{count}\"\n",
    "\n",
    "    payload = {\n",
    "        \"eventname\": speaker[\"eventname\"],\n",
    "        \"eventlocation\": speaker[\"eventlocation\"],\n",
    "        \"eventlink\": speaker[\"eventlink\"],\n",
    "        \"eventdate\": speaker[\"eventdate\"],\n",
    "        \"image\": speaker[\"image\"],\n",
    "        \"hoverimage\": speaker[\"hoverimage\"]\n",
    "    }\n",
    "\n",
    "    print(f\"Sending request to: {url}\")\n",
    "    response = requests.post(url, json=payload)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        print(f\"✅ Success (Event {count})\")\n",
    "    else:\n",
    "        print(f\"❌ Failed (Event {count})\")\n",
    "\n",
    "    print(f\"Payload: {payload}\")\n",
    "    print(f\"Response: {response.text}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    count += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df9aed8",
   "metadata": {},
   "source": [
    "# Streamlit website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f39e035",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
